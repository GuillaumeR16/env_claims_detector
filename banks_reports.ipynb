{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3beb61d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3beb61d",
    "outputId": "60837b33-f601-4da3-bce5-ff3260f06064"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (0.27.6)\n",
      "Requirement already satisfied: aiohttp in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from openai) (3.8.1)\n",
      "Requirement already satisfied: tqdm in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from requests>=2.20->openai) (2.10)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from aiohttp->openai) (21.4.0)\n",
      "Requirement already satisfied: PyPDF2 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from PyPDF2) (4.3.0)\n",
      "Requirement already satisfied: PyCryptodome in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (3.18.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/guillaume/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (4.20.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: filelock in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/guillaume/opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.12)\n"
     ]
    }
   ],
   "source": [
    "# Import standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import bs4 as bs\n",
    "import urllib.request\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "# Import for text analytics\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import string\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim import corpora\n",
    "import multiprocessing\n",
    "\n",
    "# Load English language model of spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Sklearn import\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler \n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import precision_score, recall_score, f1_score \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Import OpenAI\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')\n",
    "!pip install openai\n",
    "import openai\n",
    "\n",
    "# Other imports\n",
    "!pip install PyPDF2\n",
    "!pip install PyCryptodome\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import PyPDF2\n",
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import torch\n",
    "!pip install transformers\n",
    "import transformers as ppb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "u-N3niFTYKHz",
   "metadata": {
    "id": "u-N3niFTYKHz"
   },
   "source": [
    "\n",
    "# Introduction to the Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9V7NpgG7a1V7",
   "metadata": {
    "id": "9V7NpgG7a1V7"
   },
   "source": [
    "The primary purposes of this notebook are:\n",
    "\n",
    "- Extract text from different banks annual report \n",
    "- Applying our best and less expensive model to predict envirenmental claims in these reports \n",
    "- In conjunction with Trucost's climate data, an analysis of these annual reports is being developed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "B52N6ZKYbfjc",
   "metadata": {
    "id": "B52N6ZKYbfjc"
   },
   "source": [
    "The selected banks for analysis include:\n",
    "\n",
    "- UBS\n",
    "- Credit Suisse\n",
    "- Banque Cantonale Vaudoise\n",
    "- J.P. Morgan\n",
    "- Goldman Sachs\n",
    "\n",
    "We examined the annual reports of each bank for the years 2019 and 2020. Therefore, we use our prediction model a total of 10 times.\n",
    "\n",
    "Furthermore, we identified specific sections within these reports that were pertinent to our analysis and likely to contain environmental claims. For instance, we excluded the \"Financial Statements\" sections from all the annual reports. This process was conducted individually for each report, carefully determining which sections were relevant to our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ncGaZVIGdGZR",
   "metadata": {
    "id": "ncGaZVIGdGZR"
   },
   "source": [
    "The notebook is organized as follows:\n",
    "- To begin, we leverage our most effective and less expensive text classifier, the GPT-3 utilizing the ada model, to develop a function for fine-tuning each sentence within the annual reports. This function will enables us to predict whether a sentence from a bank's annual report qualifies as an environmental claim or not. We did not want to use the very best text classifier GPT-3 utilizing the davinci model for financial reasons.\n",
    "- Simultaneously, we extract relevant sections of the annual reports for each bank in the years 2019 and 2020. These sections are stored in dedicated dataframes specific to each bank and year. Subsequently, these dataframes are incorporated into the aforementioned GPT-3 function.\n",
    "- Towards the end of the notebook, two analyses are conducted. The first analysis focuses on individual bank CO2 emissions, comparing the emissions between different years. The second analysis centers on an industry-wide comparison, facilitated by the inclusion of the CO2 intensity metric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fWb-PxHnZymN",
   "metadata": {
    "id": "fWb-PxHnZymN"
   },
   "source": [
    "# OpenAi - Prediction Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8lLK4z_f2uV",
   "metadata": {
    "id": "c8lLK4z_f2uV"
   },
   "source": [
    "First we \"import\" our OpenAi Key. For confidentiality reasons, we cannot disclose the key within this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R00VTj5AmRH7",
   "metadata": {
    "id": "R00VTj5AmRH7"
   },
   "outputs": [],
   "source": [
    "# OpenAi key\n",
    "api_key = '***'\n",
    "openai.api_key = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NDjMQZvVgVtH",
   "metadata": {
    "id": "NDjMQZvVgVtH"
   },
   "source": [
    "In the next cell, we define a function that takes the sentences extracted from the annual reports of banks as input. The function utilizes the GPT-3 Text Classifier to make predictions and generates a dataframe containing the established predictions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0136cf",
   "metadata": {
    "id": "5b0136cf"
   },
   "outputs": [],
   "source": [
    "def openai_predictions_ada (dataframe):\n",
    "    #Transforming the dataset to fit openai's formatting\n",
    "    dataframe = dataframe.rename(columns={'Sentences':'prompt'})\n",
    "    dataframe['prompt'] = dataframe['prompt'] + '->'\n",
    "\n",
    "    # Make predictions for each sentence\n",
    "    predictions = []\n",
    "    for index, row in dataframe.iterrows():\n",
    "        new_prompt = row[\"prompt\"]\n",
    "        answer = openai.Completion.create(\n",
    "          model=\"ada:ft-personal-2023-05-20-17-34-23\",\n",
    "          prompt=new_prompt,\n",
    "          max_tokens=2,  # Adjust based on your desired prediction length\n",
    "          temperature=0,\n",
    "          top_p = 0.1\n",
    "      )\n",
    "        difficulty = answer.choices[0]['text']\n",
    "        predictions.append(difficulty)\n",
    "\n",
    "    # Add the predictions to the dataframe\n",
    "    dataframe[\"pred\"] = predictions\n",
    "    #clean the prediction column\n",
    "    dataframe['pred'] = dataframe['pred'].str.replace('.', '')\n",
    "\n",
    "    #display the dataframe once the predictions are done\n",
    "    display(dataframe)\n",
    "    display(dataframe.groupby('pred').count())\n",
    "\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VulNGM1NhJru",
   "metadata": {
    "id": "VulNGM1NhJru"
   },
   "source": [
    "# Banks Annual Reports - Predictions \n",
    "\n",
    "In this section, we conduct a thorough examination of the five banks individually for the two years being reviewed (2019 and 2020). For each bank, the process is the same. The process begins by extracting the text from each bank's annual report. Subsequently, we use the function we developed earlier to analyze and predict the content of each sentence within the extracted text. Next, we store the count of environmental claims per report in a bank- and year-specific variable.  This particular variable will be further used in our analysis that incorporates Trucost's climate data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7366ac95",
   "metadata": {
    "id": "7366ac95"
   },
   "source": [
    "## Banque cantonal Vaudoise\n",
    "\n",
    "The first bank to be investigated is the Banque Cantonale Vaudoise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccff7005",
   "metadata": {
    "id": "ccff7005"
   },
   "source": [
    "### 2020 Annual Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Qx5pY8tKGUq6",
   "metadata": {
    "id": "Qx5pY8tKGUq6"
   },
   "source": [
    "As an example, in the BCV 2020 annual report, we stop at page 76 since the subsequent sections focus on the governance structure and financial statements. It's important to note that the code's numbering does not align directly with the page numbers in the bottom right corner of the annual report. This discrepancy arises because the annual report excludes introductory pages when counting pages, unlike the \"pdf\" version. This variation persists across all the analyzed reports in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600f4d57",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "600f4d57",
    "outputId": "bac72beb-f2c5-4567-a0ec-edc3f7664862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the PDF file\n",
    "url = \"https://github.com/noelopez-E4S/class_datascience/raw/main/ENG-BCV_Rapport_annuel_2020.pdf\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the PDF file content from the response content\n",
    "    pdf_content = response.content\n",
    "    # Save the PDF file to disk\n",
    "    with open(\"BCV_annual_report_2020.pdf\", \"wb\") as f:\n",
    "        f.write(pdf_content)\n",
    "    print(\"PDF file downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to download the PDF file. Error code: {response.status_code}\")\n",
    "    \n",
    "    \n",
    "# Open the input PDF file\n",
    "infile = PdfReader(\"BCV_annual_report_2020.pdf\", \"rb\")\n",
    "\n",
    "# Create a new PDF writer\n",
    "output = PdfWriter()\n",
    "\n",
    "# Loop through all pages and add them to the new PDF writer\n",
    "for i, page in enumerate(infile.pages):\n",
    "    if (i < 76): # define which pages of the report the model has to extract --> only the relevant pages \n",
    "        output.add_page(page)\n",
    "\n",
    "# Write the output PDF to a file\n",
    "with open(\"BCV_annual_report_2020_trimmed.pdf\", \"wb\") as f:\n",
    "    output.write(f)\n",
    "    \n",
    "# Load PDF file\n",
    "pdf = PdfReader(\"BCV_annual_report_2020_trimmed.pdf\", \"rb\")\n",
    "\n",
    "# Loop through all pages and extract each sentence\n",
    "sentences = []\n",
    "for page in pdf.pages:\n",
    "    text = page.extract_text()\n",
    "    page_sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    sentences.extend(page_sentences)\n",
    "\n",
    "# Replace all '\\n' with spaces in each sentence --> Formating of the setences \n",
    "sentences = [re.sub(r\"\\n\", \" \", s) for s in sentences]\n",
    "\n",
    "# Filter out all sentences with less than 5 words\n",
    "sentences = [s for s in sentences if  5 < len(s.split()) < 50]\n",
    "\n",
    "# Create a DataFrame of the extracted sentences\n",
    "df_bcv_20 = pd.DataFrame(sentences, columns=[\"Sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dNKN94m8mf",
   "metadata": {
    "id": "94dNKN94m8mf"
   },
   "source": [
    "With all the sentences from the relevant sections of the annual reports now compiled in a dataframe, we can use the previously established function to predict each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "R4lTI2Mfosx0",
   "metadata": {
    "id": "R4lTI2Mfosx0",
    "outputId": "28341d93-6c33-4e14-c14e-bfc5618f82a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020 Annual ReportHead Office Place St-Françoi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BCV at a glance 2020 was a great year for our ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>• On 28 May 2020, we carried out a 10-for-1 st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/T_he following day, our share was added to th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We continued to implement our sustainable deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>/T_his chapter explains how the Bank puts thes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>six-exchange-regulation.com/dam/downloads/regu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>Group structure and shareholders  75 2.-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>Compensation, shareholdings, and loans  96 6.-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>Takeovers and defense measures  103 8.-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1186 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt pred\n",
       "0     2020 Annual ReportHead Office Place St-Françoi...    0\n",
       "1     BCV at a glance 2020 was a great year for our ...    0\n",
       "2     • On 28 May 2020, we carried out a 10-for-1 st...    0\n",
       "3     /T_he following day, our share was added to th...    0\n",
       "4     We continued to implement our sustainable deve...    0\n",
       "...                                                 ...  ...\n",
       "1181  /T_his chapter explains how the Bank puts thes...    0\n",
       "1182  six-exchange-regulation.com/dam/downloads/regu...    0\n",
       "1183          Group structure and shareholders  75 2.->    0\n",
       "1184    Compensation, shareholdings, and loans  96 6.->    0\n",
       "1185           Takeovers and defense measures  103 8.->    0\n",
       "\n",
       "[1186 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt\n",
       "pred        \n",
       " 0      1152\n",
       " 1        34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the prediction function\n",
    "df_bcv_20 = openai_predictions_ada(df_bcv_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "icQ5s7HjkYvA",
   "metadata": {
    "id": "icQ5s7HjkYvA"
   },
   "outputs": [],
   "source": [
    "# Storing the dataframe with predtictions --> to avoid re-running the model everytime\n",
    "df_bcv_20.to_csv('df_bcv_20_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s0oqKd0ZzDga",
   "metadata": {
    "id": "s0oqKd0ZzDga"
   },
   "source": [
    "Now we can count the number of environmental claims (label = 1) predicted by our model. This variable will be used as part of our analysis with Trucost data at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4046b6",
   "metadata": {
    "id": "fa4046b6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count the number of observation with 1 as a label\n",
    "bcv_20_env_claims = df_bcv_20[df_bcv_20['pred']==' 1'].count()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76a789b",
   "metadata": {
    "id": "b76a789b"
   },
   "source": [
    "You can find below an example of environmental and non-environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480345d",
   "metadata": {
    "id": "1480345d",
    "outputId": "b9488214-1def-4bcf-a088-9ca278a38776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green claim:  It oﬀers a broad, transparent view of what we are doing to fulﬁll our commitment to promoting economically, socially, and environmentally sustainable development.-> \n",
      "\n",
      "Non-green claim:  BCV at a glance 2020 was a great year for our share • Our share delivered a total return of 26.5% in 2020,  making it the second-best performer among Swiss  banking stocks.->\n"
     ]
    }
   ],
   "source": [
    "#Green claim\n",
    "print('Green claim: ',df_bcv_20[(df_bcv_20['pred']==' 1')].iloc[1][0],'\\n')\n",
    "\n",
    "#Non-green claim\n",
    "print('Non-green claim: ',df_bcv_20[(df_bcv_20['pred']==' 0')].iloc[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01726bac",
   "metadata": {
    "id": "01726bac"
   },
   "source": [
    "### 2019 Annual Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59268013",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "59268013",
    "outputId": "375437fe-e818-4ad5-e098-cb148d6ac85e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the PDF file\n",
    "url = \"https://github.com/noelopez-E4S/class_datascience/raw/main/ENG-BCV_Rapport_annuel_2019.pdf\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the PDF file content from the response content\n",
    "    pdf_content = response.content\n",
    "    # Save the PDF file to disk\n",
    "    with open(\"BCV_annual_report_2019.pdf\", \"wb\") as f:\n",
    "        f.write(pdf_content)\n",
    "    print(\"PDF file downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to download the PDF file. Error code: {response.status_code}\")\n",
    "    \n",
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "\n",
    "# Open the input PDF file\n",
    "infile = PdfReader(\"BCV_annual_report_2019.pdf\", \"rb\")\n",
    "\n",
    "# Create a new PDF writer\n",
    "output = PdfWriter()\n",
    "\n",
    "# Loop through all pages and add them to the new PDF writer\n",
    "for i, page in enumerate(infile.pages):\n",
    "    if (i < 72): # define which pages of the report the model has to extract --> only the relevant pages \n",
    "        output.add_page(page)\n",
    "\n",
    "# Write the output PDF to a file\n",
    "with open(\"BCV_annual_report_2019_trimmed.pdf\", \"wb\") as f:\n",
    "    output.write(f)\n",
    "    \n",
    "# Load PDF file\n",
    "pdf = PdfReader(\"BCV_annual_report_2019_trimmed.pdf\", \"rb\")\n",
    "\n",
    "# Loop through all pages and extract each sentence\n",
    "sentences = []\n",
    "for page in pdf.pages:\n",
    "    text = page.extract_text()\n",
    "    page_sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    sentences.extend(page_sentences)\n",
    "\n",
    "# Replace all '\\n' with spaces in each sentence\n",
    "sentences = [re.sub(r\"\\n\", \" \", s) for s in sentences]\n",
    "\n",
    "# Filter out all sentences with less than 5 words\n",
    "sentences = [s for s in sentences if  5 < len(s.split()) < 50]\n",
    "\n",
    "\n",
    "# Create a DataFrame of the extracted sentences\n",
    "df_bcv_19 = pd.DataFrame(sentences, columns=[\"Sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A2OJNr7ez0HI",
   "metadata": {
    "id": "A2OJNr7ez0HI"
   },
   "source": [
    "With all the sentences from the relevant sections of the annual reports now compiled in a dataframe, we can use the previously established function to predict each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3Ou7s22o-Cb",
   "metadata": {
    "id": "c3Ou7s22o-Cb",
    "outputId": "c17282f8-c075-483f-c05d-761902baccd3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BCV at a glance • We maintained or slightly ad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>• The Board of Directors is recommending that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The UNPRI are the world’s leading framework fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>• Operating profit increased 4% to CHF 419m,  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>• Net profit was up 4% to CHF 363m.-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>989</th>\n",
       "      <td>This chapter explains how the Bank puts these ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>990</th>\n",
       "      <td>six-exchange-regulation.com/dam/downloads/regu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>Group structure and shareholders  71 2.-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>Compensation, shareholdings, and loans  92 6.-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>Takeovers and defense measures  99 8.-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>994 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt pred\n",
       "0    BCV at a glance • We maintained or slightly ad...    0\n",
       "1    • The Board of Directors is recommending that ...    0\n",
       "2    The UNPRI are the world’s leading framework fo...    0\n",
       "3    • Operating profit increased 4% to CHF 419m,  ...    0\n",
       "4                • Net profit was up 4% to CHF 363m.->    0\n",
       "..                                                 ...  ...\n",
       "989  This chapter explains how the Bank puts these ...    0\n",
       "990  six-exchange-regulation.com/dam/downloads/regu...    0\n",
       "991          Group structure and shareholders  71 2.->    0\n",
       "992    Compensation, shareholdings, and loans  92 6.->    0\n",
       "993            Takeovers and defense measures  99 8.->    0\n",
       "\n",
       "[994 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt\n",
       "pred        \n",
       " 0       978\n",
       " 1        16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the prediction function\n",
    "df_bcv_19 = openai_predictions_ada(df_bcv_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gpVFd8ypmFwx",
   "metadata": {
    "id": "gpVFd8ypmFwx"
   },
   "outputs": [],
   "source": [
    "# Storing the dataframe with predtictions --> to avoid re-running the model everytime\n",
    "df_bcv_19.to_csv('df_bcv_19_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AwMasTSY0aD_",
   "metadata": {
    "id": "AwMasTSY0aD_"
   },
   "source": [
    "Now we can count the number of environmental claims (label = 1) predicted by our model. This variable will be used as part of our analysis with Trucost data at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbb05a2",
   "metadata": {
    "id": "9bbb05a2"
   },
   "outputs": [],
   "source": [
    "# Count the number of observation with 1 as a label\n",
    "bcv_19_env_claims = df_bcv_19[df_bcv_19['pred']==' 1'].count()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c26dbe",
   "metadata": {
    "id": "d5c26dbe"
   },
   "source": [
    "You can find below an example of environmental and non-environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f657f9d",
   "metadata": {
    "id": "8f657f9d",
    "outputId": "175fa991-1701-4029-9368-c0c2f4b7f196"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green claim:  Beyond these events, we see this anniversary as an  opportunity to highlight BCV’s core guiding principles: close  ties with the community we serve and a commitment to  contributing to our home region by fostering economically,  environmentally, and socially sustainable development.-> \n",
      "\n",
      "Non-green claim:  • The Board of Directors is recommending that shareholders approve a 10-for-1 stock split, in order to  enhance the liquidity of BCV’s share.->\n"
     ]
    }
   ],
   "source": [
    "#Green claim\n",
    "print('Green claim: ',df_bcv_19[(df_bcv_19['pred']==' 1')].iloc[1][0],'\\n')\n",
    "\n",
    "#Non-green claim\n",
    "print('Non-green claim: ',df_bcv_19[(df_bcv_19['pred']==' 0')].iloc[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbf5559",
   "metadata": {
    "id": "5bbf5559"
   },
   "source": [
    "## UBS\n",
    "\n",
    "The second bank to be investigated is UBS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db2ece4",
   "metadata": {
    "id": "3db2ece4"
   },
   "source": [
    "### 2020 Annual Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd80373",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbd80373",
    "outputId": "4b237af0-c0a5-45c3-ff7f-01ba7042df9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the PDF file\n",
    "url = \"https://github.com/noelopez-E4S/class_datascience/raw/main/full-report-ubs-group-ag-consolidated-2020-en.pdf\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the PDF file content from the response content\n",
    "    pdf_content = response.content\n",
    "    # Save the PDF file to disk\n",
    "    with open(\"UBS_annual_report_2020.pdf\", \"wb\") as f:\n",
    "        f.write(pdf_content)\n",
    "    print(\"PDF file downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to download the PDF file. Error code: {response.status_code}\")\n",
    "    \n",
    "    \n",
    "# Open the input PDF file\n",
    "infile = PdfReader(\"UBS_annual_report_2020.pdf\", \"rb\")\n",
    "\n",
    "# Create a new PDF writer\n",
    "output = PdfWriter()\n",
    "\n",
    "# Loop through all pages and add them to the new PDF writer\n",
    "for i, page in enumerate(infile.pages):\n",
    "    if (i < 73) or (143 <= i <= 144): # define which pages of the report the model has to extract --> only the relevant pages \n",
    "        output.add_page(page)\n",
    "\n",
    "# Write the output PDF to a file\n",
    "with open(\"UBS_annual_report_2020_trimmed.pdf\", \"wb\") as f:\n",
    "    output.write(f)\n",
    "    \n",
    "# Load PDF file\n",
    "pdf = PdfReader(\"UBS_annual_report_2020_trimmed.pdf\", \"rb\")\n",
    "\n",
    "# Loop through all pages and extract each sentence\n",
    "sentences = []\n",
    "for page in pdf.pages:\n",
    "    text = page.extract_text()\n",
    "    page_sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    sentences.extend(page_sentences)\n",
    "\n",
    "# Replace all '\\n' with spaces in each sentence\n",
    "sentences = [re.sub(r\"\\n\", \" \", s) for s in sentences]\n",
    "\n",
    "# Filter out all sentences with less than 5 words. \n",
    "sentences = [s for s in sentences if  5 < len(s.split()) < 50]\n",
    "\n",
    "\n",
    "# Create a DataFrame of the extracted sentences\n",
    "df_ubs_20 = pd.DataFrame(sentences, columns=[\"Sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6y0HqdPXz1mZ",
   "metadata": {
    "id": "6y0HqdPXz1mZ"
   },
   "source": [
    "With all the sentences from the relevant sections of the annual reports now compiled in a dataframe, we can use the previously established function to predict each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hD1vrRwTnDSv",
   "metadata": {
    "id": "hD1vrRwTnDSv",
    "outputId": "5a53fa96-5204-4b28-8059-4df8e28c0803"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UBS Group AG Annual Report 2020-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>We also provide a combined annual report for  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We provide our combined Annual Report, the Pil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The reports are presented in US dollars, our p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The UBS Group AG Annual Report 2020 is partly ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>Cross-border risk remains an area of regulator...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>There is also ongoing high attention on the ri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>UBS actively assesses and  applies permanent e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2038</th>\n",
       "      <td>During 2020, thanks to the continued focus on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>Risk, capital, liquidity and funding,   and ba...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2040 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt pred\n",
       "0                     UBS Group AG Annual Report 2020->    0\n",
       "1     We also provide a combined annual report for  ...    0\n",
       "2     We provide our combined Annual Report, the Pil...    0\n",
       "3     The reports are presented in US dollars, our p...    0\n",
       "4     The UBS Group AG Annual Report 2020 is partly ...    0\n",
       "...                                                 ...  ...\n",
       "2035  Cross-border risk remains an area of regulator...    0\n",
       "2036  There is also ongoing high attention on the ri...    0\n",
       "2037  UBS actively assesses and  applies permanent e...    0\n",
       "2038  During 2020, thanks to the continued focus on ...    0\n",
       "2039  Risk, capital, liquidity and funding,   and ba...    0\n",
       "\n",
       "[2040 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt\n",
       "pred        \n",
       " 0      1955\n",
       " 1        85"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the prediction function\n",
    "df_ubs_20 = openai_predictions_ada(df_ubs_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hvELWJ7dpnvr",
   "metadata": {
    "id": "hvELWJ7dpnvr"
   },
   "outputs": [],
   "source": [
    "# Storing the dataframe with predtictions --> to avoid re-running the model everytime\n",
    "df_ubs_20.to_csv('df_ubs_20_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2tfEffVr0cEH",
   "metadata": {
    "id": "2tfEffVr0cEH"
   },
   "source": [
    "Now we can count the number of environmental claims (label = 1) predicted by our model. This variable will be used as part of our analysis with Trucost data at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1eb90a1",
   "metadata": {
    "id": "e1eb90a1"
   },
   "outputs": [],
   "source": [
    "# Count the number of observation with 1 as a label\n",
    "ubs_20_env_claims = df_ubs_20[df_ubs_20['pred']==' 1'].count()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237c7069",
   "metadata": {
    "id": "237c7069"
   },
   "source": [
    "You can find below an example of environmental and non-environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b13dfc",
   "metadata": {
    "id": "a6b13dfc",
    "outputId": "eab279e2-0b1d-4558-c038-d1e9a7ca2c51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green claim:  We delivered the best of UBS to our clients and  extended our leadership in sustainability.-> \n",
      "\n",
      "Non-green claim:  We also provide a combined annual report for  UBS Group AG and UBS AG consolidated, which additionally  includes the consolidated financial statements of UBS AG as  well as supplemental disclosures required under SEC  regulations and is the basis for our SEC Form 20-F filing.->\n"
     ]
    }
   ],
   "source": [
    "#Green claim\n",
    "print('Green claim: ',df_ubs_20[(df_ubs_20['pred']==' 1')].iloc[1][0],'\\n')\n",
    "\n",
    "#Non-green claim\n",
    "print('Non-green claim: ',df_ubs_20[(df_ubs_20['pred']==' 0')].iloc[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd1ce3",
   "metadata": {
    "id": "1cbd1ce3"
   },
   "source": [
    "### 2019 Annual Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d22900",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b4d22900",
    "outputId": "df622874-5fd2-4dfd-c836-f9dc6da5836a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the PDF file\n",
    "url = \"https://github.com/noelopez-E4S/class_datascience/raw/main/full-report-ubs-group-ag-consolidated-2019-en.pdf\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the PDF file content from the response content\n",
    "    pdf_content = response.content\n",
    "    # Save the PDF file to disk\n",
    "    with open(\"UBS_annual_report_2019.pdf\", \"wb\") as f:\n",
    "        f.write(pdf_content)\n",
    "    print(\"PDF file downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to download the PDF file. Error code: {response.status_code}\")\n",
    "    \n",
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "\n",
    "# Open the input PDF file\n",
    "infile = PdfReader(\"UBS_annual_report_2019.pdf\", \"rb\")\n",
    "\n",
    "# Create a new PDF writer\n",
    "output = PdfWriter()\n",
    "\n",
    "# Loop through all pages and add them to the new PDF writer\n",
    "for i, page in enumerate(infile.pages):\n",
    "    if (i < 77) or (i == 118) or (i == 113): # define which pages of the report the model has to extract --> only the relevant pages \n",
    "        output.add_page(page)\n",
    "\n",
    "# Write the output PDF to a file\n",
    "with open(\"UBS_annual_report_2019_trimmed.pdf\", \"wb\") as f:\n",
    "    output.write(f)\n",
    "    \n",
    "# Load PDF file\n",
    "pdf = PdfReader(\"UBS_annual_report_2019_trimmed.pdf\", \"rb\")\n",
    "\n",
    "# Loop through all pages and extract each sentence\n",
    "sentences = []\n",
    "for page in pdf.pages:\n",
    "    text = page.extract_text()\n",
    "    page_sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    sentences.extend(page_sentences)\n",
    "\n",
    "# Replace all '\\n' with spaces in each sentence\n",
    "sentences = [re.sub(r\"\\n\", \" \", s) for s in sentences]\n",
    "\n",
    "# Filter out all sentences with less than 5 words.\n",
    "sentences = [s for s in sentences if  5 < len(s.split()) < 50]\n",
    "\n",
    "\n",
    "# Create a DataFrame of the extracted sentences\n",
    "df_ubs_19 = pd.DataFrame(sentences, columns=[\"Sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AQzWuvOaz3BC",
   "metadata": {
    "id": "AQzWuvOaz3BC"
   },
   "source": [
    "With all the sentences from the relevant sections of the annual reports now compiled in a dataframe, we can use the previously established function to predict each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gPf8Q7-onK3x",
   "metadata": {
    "id": "gPf8Q7-onK3x",
    "outputId": "2e5904fe-4a3a-4c1b-c9df-145523a1ab3c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UBS Group AG  Annual Report 2019-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annual reporting At the center of our external...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>We also provide a combined annual report for U...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The reports are presented in US dollars, our p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The UBS Group AG Annual Report 2019 is transla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1453</th>\n",
       "      <td>Heightened regulatory expectations and attenti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>Refer to “Operational risk” in this section an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>We make use of both scenario-based stress test...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>These complementary frameworks  \u0014\u0012\u0013\u001b\u0002SWCPVKVCV...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td> Refer to “Risk measurement” in this section ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1458 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt pred\n",
       "0                    UBS Group AG  Annual Report 2019->    0\n",
       "1     Annual reporting At the center of our external...    0\n",
       "2     We also provide a combined annual report for U...    0\n",
       "3     The reports are presented in US dollars, our p...    0\n",
       "4     The UBS Group AG Annual Report 2019 is transla...    0\n",
       "...                                                 ...  ...\n",
       "1453  Heightened regulatory expectations and attenti...    0\n",
       "1454  Refer to “Operational risk” in this section an...    0\n",
       "1455  We make use of both scenario-based stress test...    0\n",
       "1456  These complementary frameworks  \u0014\u0012\u0013\u001b\u0002SWCPVKVCV...    0\n",
       "1457   Refer to “Risk measurement” in this section ...    0\n",
       "\n",
       "[1458 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt\n",
       "pred        \n",
       " 0      1392\n",
       " 1        66"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the prediction function\n",
    "df_ubs_19 = openai_predictions_ada(df_ubs_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Zz8j_kldqdZm",
   "metadata": {
    "id": "Zz8j_kldqdZm"
   },
   "outputs": [],
   "source": [
    "# Storing the dataframe with predtictions --> to avoid re-running the model everytime\n",
    "df_ubs_19.to_csv('df_ubs_19_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s-A85dDi0d_S",
   "metadata": {
    "id": "s-A85dDi0d_S"
   },
   "source": [
    "Now we can count the number of environmental claims (label = 1) predicted by our model. This variable will be used as part of our analysis with Trucost data at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede31191",
   "metadata": {
    "id": "ede31191"
   },
   "outputs": [],
   "source": [
    "# Count the number of observation with 1 as a label\n",
    "ubs_19_env_claims =  df_ubs_19[df_ubs_19['pred']==' 1'].count()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf7961",
   "metadata": {
    "id": "a6bf7961"
   },
   "source": [
    "You can find below an example of environmental and non-environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13fadd9",
   "metadata": {
    "id": "f13fadd9",
    "outputId": "e4c00632-8fba-4065-c3ec-a516a84b0838"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green claim:  Society and environment  • USD 488.5 billion of sustainable investing assets (13.5% of our total invested assets).-> \n",
      "\n",
      "Non-green claim:  Annual reporting At the center of our external reporting approach is the  annual report of UBS Group AG, which consists of disclosures for UBS Group AG and its consolidated subsidiaries.->\n"
     ]
    }
   ],
   "source": [
    "#Green claim\n",
    "print('Green claim: ',df_ubs_19[(df_ubs_19['pred']==' 1')].iloc[1][0],'\\n')\n",
    "\n",
    "#Non-green claim\n",
    "print('Non-green claim: ',df_ubs_19[(df_ubs_19['pred']==' 0')].iloc[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c626dd6",
   "metadata": {
    "id": "2c626dd6"
   },
   "source": [
    "## Crédit Suisse \n",
    "\n",
    "The third bank to be investigated is Crédit Suisse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d91b006",
   "metadata": {
    "id": "3d91b006"
   },
   "source": [
    "### 2020 Annual Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7cedd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03b7cedd",
    "outputId": "7df7fabf-9f67-4d9c-f26f-be0db3c6b68f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the PDF file\n",
    "url = \"https://github.com/noelopez-E4S/class_datascience/raw/main/csg-ar-2020-en.pdf\"\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the PDF file content from the response content\n",
    "    pdf_content = response.content\n",
    "    # Save the PDF file to disk\n",
    "    with open(\"CS_annual_report_2020.pdf\", \"wb\") as f:\n",
    "        f.write(pdf_content)\n",
    "    print(\"PDF file downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to download the PDF file. Error code: {response.status_code}\")\n",
    "    \n",
    "    \n",
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "\n",
    "# Open the input PDF file\n",
    "infile = PdfReader(\"CS_annual_report_2020.pdf\", \"rb\")\n",
    "\n",
    "# Create a new PDF writer\n",
    "output = PdfWriter()\n",
    "\n",
    "# Loop through all pages and add them to the new PDF writer\n",
    "for i, page in enumerate(infile.pages):\n",
    "    if (i < 60) or (141 <= i <= 181): # define which pages of the report the model has to extract --> only the relevant pages \n",
    "        output.add_page(page)\n",
    "\n",
    "# Write the output PDF to a file\n",
    "with open(\"CS_annual_report_2020_trimmed.pdf\", \"wb\") as f:\n",
    "    output.write(f)\n",
    "    \n",
    "    \n",
    "# Load PDF file\n",
    "pdf = PdfReader(\"CS_annual_report_2020_trimmed.pdf\", \"rb\")\n",
    "\n",
    "# Loop through all pages and extract each sentence\n",
    "sentences = []\n",
    "for page in pdf.pages:\n",
    "    text = page.extract_text()\n",
    "    page_sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    sentences.extend(page_sentences)\n",
    "\n",
    "# Replace all '\\n' with spaces in each sentence\n",
    "sentences = [re.sub(r\"\\n\", \" \", s) for s in sentences]\n",
    "\n",
    "# Filter out all sentences with less than 5 words\n",
    "sentences = [s for s in sentences if  5 < len(s.split()) < 50]\n",
    "\n",
    "\n",
    "# Create a DataFrame of the extracted sentences\n",
    "df_cs_20 = pd.DataFrame(sentences, columns=[\"Sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cu3v3q00z65v",
   "metadata": {
    "id": "cu3v3q00z65v"
   },
   "source": [
    "With all the sentences from the relevant sections of the annual reports now compiled in a dataframe, we can use the previously established function to predict each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XC7okwQAdFQW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "XC7okwQAdFQW",
    "outputId": "6d4db21a-9398-4c9c-e445-e9dfdfa918e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit Suisse Group AG Annual Report 2020-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annual Report 2020 Credit Suisse Group AG-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the purposes of this report, unless the c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The business of Credit Suisse AG, the direct b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We use the term the “Bank” when we are referri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>Representations and warranties on residential ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>We have provided these representations and war...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>The loans sold are primarily loans that we hav...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>If it is determined that rep - resentations an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>Whether we will incur a loss in con - nection ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2168 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt pred\n",
       "0           Credit Suisse Group AG Annual Report 2020->    0\n",
       "1           Annual Report 2020 Credit Suisse Group AG->    0\n",
       "2      For the purposes of this report, unless the c...    0\n",
       "3     The business of Credit Suisse AG, the direct b...    0\n",
       "4     We use the term the “Bank” when we are referri...    0\n",
       "...                                                 ...  ...\n",
       "2163  Representations and warranties on residential ...    0\n",
       "2164  We have provided these representations and war...    0\n",
       "2165  The loans sold are primarily loans that we hav...    0\n",
       "2166  If it is determined that rep - resentations an...    0\n",
       "2167  Whether we will incur a loss in con - nection ...    0\n",
       "\n",
       "[2168 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt\n",
       "pred        \n",
       " 0      2139\n",
       " 1        29"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the prediction function\n",
    "df_cs_20 = openai_predictions_ada(df_cs_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daiseFfggLd_",
   "metadata": {
    "id": "daiseFfggLd_"
   },
   "outputs": [],
   "source": [
    "# Storing the dataframe with predtictions --> to avoid re-running the model everytime\n",
    "df_cs_20.to_csv('df_cs_20_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zPWcVNrG0frj",
   "metadata": {
    "id": "zPWcVNrG0frj"
   },
   "source": [
    "Now we can count the number of environmental claims (label = 1) predicted by our model. This variable will be used as part of our analysis with Trucost data at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f003bd9c",
   "metadata": {
    "id": "f003bd9c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Count the number of observation with 1 as a label\n",
    "cs_20_env_claims = df_cs_20[df_cs_20['pred']==' 1'].count()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e3d429",
   "metadata": {
    "id": "10e3d429"
   },
   "source": [
    "You can find below an example of environmental and non-environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2562614",
   "metadata": {
    "id": "b2562614",
    "outputId": "f08d4de2-0574-40a0-d1da-dfaf953d2fcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green claim:  We launched a new Sustainability, Research & Investment Solutions (SRI) function at the Executive Board level, underlining the sharpened focus on sustainability.-> \n",
      "\n",
      "Non-green claim:  This was  a decline of 22% year on year including primarily the effects of  higher provision for credit losses and major litigation provisions, as well as the impairment to the valuation of our minority sharehold - ing in York Capital Management.->\n"
     ]
    }
   ],
   "source": [
    "#Green claim\n",
    "print('Green claim: ',df_cs_20[(df_cs_20['pred']==' 1')].iloc[1][0],'\\n')\n",
    "\n",
    "#Non-green claim\n",
    "print('Non-green claim: ',df_cs_20[(df_cs_20['pred']==' 0')].iloc[30][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2ff33a",
   "metadata": {
    "id": "8a2ff33a"
   },
   "source": [
    "### 2019 Annual Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960245de",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "960245de",
    "outputId": "26883240-0397-4e5b-8dbb-05f354ed03c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the PDF file\n",
    "url = \"https://github.com/noelopez-E4S/class_datascience/raw/main/csg-ar-2019-en.pdf\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the PDF file content from the response content\n",
    "    pdf_content = response.content\n",
    "    # Save the PDF file to disk\n",
    "    with open(\"CS_annual_report_2019.pdf\", \"wb\") as f:\n",
    "        f.write(pdf_content)\n",
    "    print(\"PDF file downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to download the PDF file. Error code: {response.status_code}\")\n",
    "    \n",
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "\n",
    "# Open the input PDF file\n",
    "infile = PdfReader(\"CS_annual_report_2019.pdf\", \"rb\")\n",
    "\n",
    "# Create a new PDF writer\n",
    "output = PdfWriter()\n",
    "\n",
    "# Loop through all pages and add them to the new PDF writer\n",
    "for i, page in enumerate(infile.pages):\n",
    "    if (i < 55) or (137 <= i <= 159): # define which pages of the report the model has to extract --> only the relevant pages \n",
    "        output.add_page(page)\n",
    "\n",
    "# Write the output PDF to a file\n",
    "with open(\"CS_annual_report_2019_trimmed.pdf\", \"wb\") as f:\n",
    "    output.write(f)\n",
    "    \n",
    "# Load PDF file\n",
    "pdf = PdfReader(\"CS_annual_report_2019_trimmed.pdf\", \"rb\")\n",
    "\n",
    "# Loop through all pages and extract each sentence\n",
    "sentences = []\n",
    "for page in pdf.pages:\n",
    "    text = page.extract_text()\n",
    "    page_sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    sentences.extend(page_sentences)\n",
    "\n",
    "# Replace all '\\n' with spaces in each sentence\n",
    "sentences = [re.sub(r\"\\n\", \" \", s) for s in sentences]\n",
    "\n",
    "# Filter out all sentences with less than 5 words\n",
    "sentences = [s for s in sentences if  5 < len(s.split()) < 50]\n",
    "\n",
    "\n",
    "# Create a DataFrame of the extracted sentences\n",
    "df_cs_19 = pd.DataFrame(sentences, columns=[\"Sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HDIt72rNz8XM",
   "metadata": {
    "id": "HDIt72rNz8XM"
   },
   "source": [
    "With all the sentences from the relevant sections of the annual reports now compiled in a dataframe, we can use the previously established function to predict each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SKC2Y6vjgabl",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "SKC2Y6vjgabl",
    "outputId": "86c61444-7587-4dad-9333-4e1d1dd53c74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit Suisse Group AG Annual Report 2019-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annual Report 2019 Credit Suisse Group AG-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the purposes of this report, unless the c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The business of Credit Suisse AG, the direct b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We use the term the “Bank” when we are referri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1749</th>\n",
       "      <td>Governance of fiduciary riskSound governance i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1750</th>\n",
       "      <td>Our program targets daily, monthly or quarterl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1751</th>\n",
       "      <td>Formal review meetings are in place  to ensure...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1752</th>\n",
       "      <td>Pension risk Definition and sources of pension...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1753</th>\n",
       "      <td>It is the risk that we may be required to make...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1754 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt pred\n",
       "0           Credit Suisse Group AG Annual Report 2019->    0\n",
       "1           Annual Report 2019 Credit Suisse Group AG->    0\n",
       "2      For the purposes of this report, unless the c...    0\n",
       "3     The business of Credit Suisse AG, the direct b...    0\n",
       "4     We use the term the “Bank” when we are referri...    0\n",
       "...                                                 ...  ...\n",
       "1749  Governance of fiduciary riskSound governance i...    0\n",
       "1750  Our program targets daily, monthly or quarterl...    0\n",
       "1751  Formal review meetings are in place  to ensure...    0\n",
       "1752  Pension risk Definition and sources of pension...    0\n",
       "1753  It is the risk that we may be required to make...    0\n",
       "\n",
       "[1754 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt\n",
       "pred        \n",
       " 0      1733\n",
       " 1        21"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the prediction function\n",
    "df_cs_19 = openai_predictions_ada(df_cs_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "MQBAdIQ6hULQ",
   "metadata": {
    "id": "MQBAdIQ6hULQ"
   },
   "outputs": [],
   "source": [
    "# Storing the dataframe with predtictions --> to avoid re-running the model everytime\n",
    "df_cs_19.to_csv('df_cs_19_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dr-88ds-0is3",
   "metadata": {
    "id": "dr-88ds-0is3"
   },
   "source": [
    "Now we can count the number of environmental claims (label = 1) predicted by our model. This variable will be used as part of our analysis with Trucost data at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84e35d8",
   "metadata": {
    "id": "a84e35d8"
   },
   "outputs": [],
   "source": [
    "# Count the number of observation with 1 as a label\n",
    "cs_19_env_claims = df_cs_19[df_cs_19['pred']==' 1'].count()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5e713c",
   "metadata": {
    "id": "6e5e713c"
   },
   "source": [
    "You can find below an example of environmental and non-environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc2cac6",
   "metadata": {
    "id": "efc2cac6",
    "outputId": "64704f48-2efa-4b3b-cbbd-ff46bc4e527e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green claim:  Second, we are focusing  on delivering sustainable finance solutions that help our clients  achieve their goals and contribute to the realization of the UN Sustainable Development Goals (SDGs).-> \n",
      "\n",
      "Non-green claim:  According to the Credit Suisse Global Wealth Report  2019, the global pool of wealth grew once again between mid-2018 and mid-2019, increasing by 2.6%.->\n"
     ]
    }
   ],
   "source": [
    "#Green claim\n",
    "print('Green claim: ',df_cs_19[(df_cs_19['pred']==' 1')].iloc[1][0],'\\n')\n",
    "\n",
    "#Non-green claim\n",
    "print('Non-green claim: ',df_cs_19[(df_cs_19['pred']==' 0')].iloc[30][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39541251",
   "metadata": {
    "id": "39541251"
   },
   "source": [
    "## J.P. Morgan\n",
    "\n",
    "The fourth bank to be investigated is J.P. Morgan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a4d686",
   "metadata": {
    "id": "61a4d686"
   },
   "source": [
    "### Annual Report 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026a6eb8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "026a6eb8",
    "outputId": "25116ff4-5c24-4f4d-cd68-d53ba9d58232",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the PDF file\n",
    "url = \"https://github.com/noelopez-E4S/class_datascience/raw/main/JPM_annualreport-2020.pdf\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the PDF file content from the response content\n",
    "    pdf_content = response.content\n",
    "    # Save the PDF file to disk\n",
    "    with open(\"JPM_annual_report_2020.pdf\", \"wb\") as f:\n",
    "        f.write(pdf_content)\n",
    "    print(\"PDF file downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to download the PDF file. Error code: {response.status_code}\")\n",
    "    \n",
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "\n",
    "# Open the input PDF file\n",
    "infile = PdfReader(\"JPM_annual_report_2020.pdf\", \"rb\")\n",
    "\n",
    "# Create a new PDF writer\n",
    "output = PdfWriter()\n",
    "\n",
    "# Loop through all pages and add them to the new PDF writer\n",
    "for i, page in enumerate(infile.pages):\n",
    "    if (i < 97): # define which pages of the report the model has to extract --> only the relevant pages \n",
    "        output.add_page(page)\n",
    "\n",
    "# Write the output PDF to a file\n",
    "with open(\"JPM_annual_report_2020_trimmed.pdf\", \"wb\") as f:\n",
    "    output.write(f)\n",
    "    \n",
    "# Load PDF file\n",
    "pdf = PdfReader(\"JPM_annual_report_2020_trimmed.pdf\", \"rb\")\n",
    "\n",
    "# Loop through all pages and extract each sentence\n",
    "sentences = []\n",
    "for page in pdf.pages:\n",
    "    text = page.extract_text()\n",
    "    page_sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    sentences.extend(page_sentences)\n",
    "\n",
    "# Replace all '\\n' with spaces in each sentence\n",
    "sentences = [re.sub(r\"\\n\", \" \", s) for s in sentences]\n",
    "\n",
    "# Filter out all sentences with less than 5 words\n",
    "sentences = [s for s in sentences if  5 < len(s.split()) < 50]\n",
    "\n",
    "\n",
    "# Create a DataFrame of the extracted sentences\n",
    "df_jpm_20 = pd.DataFrame(sentences, columns=[\"Sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gBX250wEz-UL",
   "metadata": {
    "id": "gBX250wEz-UL"
   },
   "source": [
    "With all the sentences from the relevant sections of the annual reports now compiled in a dataframe, we can use the previously established function to predict each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OXRhsjKtiN9U",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "OXRhsjKtiN9U",
    "outputId": "4a5b73c6-03fc-4252-b1d5-bcf3c33dd35f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>more than loans funded280K to advance  racial ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Refer to Explanation and Reconciliation of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(b)   Refer to Liquidity Risk Management on pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(c)   The ratios presented are calculated unde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Refer to Capital Risk Management on pages 91–1...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>As of February 19 ,  2021, the Firm has funded...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>Beginning in March 2020, the  Federal Reserve ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>The Firm has participated and is participating...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>Refer to Capital Risk  Management on pages 91-...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>JPMorgan Chase &amp; Co./2020 Form 10-K 53-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1986 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt pred\n",
       "0     more than loans funded280K to advance  racial ...    0\n",
       "1     Refer to Explanation and Reconciliation of the...    0\n",
       "2     (b)   Refer to Liquidity Risk Management on pa...    0\n",
       "3     (c)   The ratios presented are calculated unde...    0\n",
       "4     Refer to Capital Risk Management on pages 91–1...    0\n",
       "...                                                 ...  ...\n",
       "1981  As of February 19 ,  2021, the Firm has funded...    0\n",
       "1982  Beginning in March 2020, the  Federal Reserve ...    0\n",
       "1983  The Firm has participated and is participating...    0\n",
       "1984  Refer to Capital Risk  Management on pages 91-...    0\n",
       "1985           JPMorgan Chase & Co./2020 Form 10-K 53->    0\n",
       "\n",
       "[1986 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt\n",
       "pred        \n",
       " 0      1964\n",
       " 1        22"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the prediction function\n",
    "df_jpm_20 = openai_predictions_ada(df_jpm_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Au9ZCGBwiYoX",
   "metadata": {
    "id": "Au9ZCGBwiYoX"
   },
   "outputs": [],
   "source": [
    "# Storing the dataframe with predtictions --> to avoid re-running the model everytime\n",
    "df_jpm_20.to_csv('df_jpm_20_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436Hdmfu0j_7",
   "metadata": {
    "id": "436Hdmfu0j_7"
   },
   "source": [
    "Now we can count the number of environmental claims (label = 1) predicted by our model. This variable will be used as part of our analysis with Trucost data at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90003ef2",
   "metadata": {
    "id": "90003ef2"
   },
   "outputs": [],
   "source": [
    "# Count the number of observation with 1 as a label\n",
    "jpm_20_env_claims = df_jpm_20[df_jpm_20['pred']==' 1'].count()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa657b64",
   "metadata": {
    "id": "aa657b64"
   },
   "source": [
    "You can find below an example of environmental and non-environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c1b48",
   "metadata": {
    "id": "364c1b48",
    "outputId": "a158da21-f9b3-4b27-8eda-eaa988827356"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green claim:  We respect the people in  our communities and protect the environment by embracing sustainable  practices across our businesses.-> \n",
      "\n",
      "Non-green claim:  As you know, we have long cham - pioned the essential role of banking in a community — its potential for bringing  people together, for enabling companies and individuals to reach for their dreams,->\n"
     ]
    }
   ],
   "source": [
    "#Green claim\n",
    "print('Green claim: ',df_jpm_20[(df_jpm_20['pred']==' 1')].iloc[1][0],'\\n')\n",
    "\n",
    "#Non-green claim\n",
    "print('Non-green claim: ',df_jpm_20[(df_jpm_20['pred']==' 0')].iloc[18][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6644b909",
   "metadata": {
    "id": "6644b909"
   },
   "source": [
    "### Annual Report 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7c1ce4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4d7c1ce4",
    "outputId": "e1755302-e32a-46aa-f98a-6aeae8ef9f69"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the PDF file\n",
    "url = \"https://github.com/noelopez-E4S/class_datascience/raw/main/JPM_annualreport-2019.pdf\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the PDF file content from the response content\n",
    "    pdf_content = response.content\n",
    "    # Save the PDF file to disk\n",
    "    with open(\"JPM_annual_report_2019.pdf\", \"wb\") as f:\n",
    "        f.write(pdf_content)\n",
    "    print(\"PDF file downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to download the PDF file. Error code: {response.status_code}\")\n",
    "    \n",
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "\n",
    "# Open the input PDF file\n",
    "infile = PdfReader(\"JPM_annual_report_2019.pdf\", \"rb\")\n",
    "\n",
    "# Create a new PDF writer\n",
    "output = PdfWriter()\n",
    "\n",
    "# Loop through all pages and add them to the new PDF writer\n",
    "for i, page in enumerate(infile.pages):\n",
    "    if (i < 51): # define which pages of the report the model has to extract --> only the relevant pages \n",
    "        output.add_page(page)\n",
    "\n",
    "# Write the output PDF to a file\n",
    "with open(\"JPM_annual_report_2019_trimmed.pdf\", \"wb\") as f:\n",
    "    output.write(f)\n",
    "    \n",
    "# Load PDF file\n",
    "pdf = PdfReader(\"JPM_annual_report_2019_trimmed.pdf\", \"rb\")\n",
    "\n",
    "# Loop through all pages and extract each sentence\n",
    "sentences = []\n",
    "for page in pdf.pages:\n",
    "    text = page.extract_text()\n",
    "    page_sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    sentences.extend(page_sentences)\n",
    "\n",
    "# Replace all '\\n' with spaces in each sentence\n",
    "sentences = [re.sub(r\"\\n\", \" \", s) for s in sentences]\n",
    "\n",
    "# Filter out all sentences with less than 5 words\n",
    "sentences = [s for s in sentences if  5 < len(s.split()) < 50]\n",
    "\n",
    "\n",
    "# Create a DataFrame of the extracted sentences\n",
    "df_jpm_19 = pd.DataFrame(sentences, columns=[\"Sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Fs0C68Lez_2U",
   "metadata": {
    "id": "Fs0C68Lez_2U"
   },
   "source": [
    "With all the sentences from the relevant sections of the annual reports now compiled in a dataframe, we can use the previously established function to predict each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Sw782HJhjO2Y",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "Sw782HJhjO2Y",
    "outputId": "0ddf7a16-d959-42bd-f0ac-3686f13d18c9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Refer to Explanation and Reconciliation of the...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(b)   Refer to Liquidity Risk Management on pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(c)   The ratios presented are calculated unde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Refer to Capital Risk Management on pages 85-9...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JPMorgan Chase &amp; Co. (NYSE: JPM) is a leading ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>The U.S . Treasur y Depar tmen t has issued pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>Under the pr oposed r egulations, amendmen ts ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>The F irm c ontinues to monitor the tr ansitio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>The F irm also c ontinues to de velop and impl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>The  Firm will c ontinue to en gage with r egu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>801 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt pred\n",
       "0    Refer to Explanation and Reconciliation of the...    0\n",
       "1    (b)   Refer to Liquidity Risk Management on pa...    0\n",
       "2    (c)   The ratios presented are calculated unde...    0\n",
       "3    Refer to Capital Risk Management on pages 85-9...    0\n",
       "4    JPMorgan Chase & Co. (NYSE: JPM) is a leading ...    0\n",
       "..                                                 ...  ...\n",
       "796  The U.S . Treasur y Depar tmen t has issued pr...    0\n",
       "797  Under the pr oposed r egulations, amendmen ts ...    0\n",
       "798  The F irm c ontinues to monitor the tr ansitio...    0\n",
       "799  The F irm also c ontinues to de velop and impl...    0\n",
       "800  The  Firm will c ontinue to en gage with r egu...    0\n",
       "\n",
       "[801 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt\n",
       "pred        \n",
       " 0       791\n",
       " 1        10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the prediction function\n",
    "df_jpm_19 = openai_predictions_ada(df_jpm_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "njFSK0KsjXsA",
   "metadata": {
    "id": "njFSK0KsjXsA"
   },
   "outputs": [],
   "source": [
    "# Storing the dataframe with predtictions --> to avoid re-running the model everytime\n",
    "df_jpm_19.to_csv('df_jpm_19_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jc0tylHM0llv",
   "metadata": {
    "id": "Jc0tylHM0llv"
   },
   "source": [
    "Now we can count the number of environmental claims (label = 1) predicted by our model. This variable will be used as part of our analysis with Trucost data at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f00d713",
   "metadata": {
    "id": "0f00d713"
   },
   "outputs": [],
   "source": [
    "# Count the number of observation with 1 as a label\n",
    "jpm_19_env_claims = df_jpm_19[df_jpm_19['pred']==' 1'].count()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e981e",
   "metadata": {
    "id": "ec4e981e"
   },
   "source": [
    "You can find below an example of environmental and non-environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805cec3",
   "metadata": {
    "id": "e805cec3",
    "outputId": "b16557c9-1667-4d9f-9386-b3b7ea618954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green claim:  Over the last five years, for example,  we’ve used technology and machine learning to reduce fraud losses in the credit card business by 50%.-> \n",
      "\n",
      "Non-green claim:  Looking back on the last two decades — starting from my time as CEO of Bank  One in 2000 — the firm has weathered some unprecedented challenges, as we  will with this current pandemic, but they did not stop us from accomplishing  some extraordinary things.->\n"
     ]
    }
   ],
   "source": [
    "#Green claim\n",
    "print('Green claim: ',df_jpm_19[(df_jpm_19['pred']==' 1')].iloc[1][0],'\\n')\n",
    "\n",
    "#Non-green claim\n",
    "print('Non-green claim: ',df_jpm_19[(df_jpm_19['pred']==' 0')].iloc[19][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3dfeff",
   "metadata": {
    "id": "bc3dfeff"
   },
   "source": [
    "## Goldman Sachs\n",
    "The fifth bank to be investigated is Goldman Sachs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db87180",
   "metadata": {
    "id": "3db87180"
   },
   "source": [
    "### Annual Report 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6c8233",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3f6c8233",
    "outputId": "31a2d7c2-0384-490e-8b72-cec17c8f4ed0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the PDF file\n",
    "url = \"https://github.com/noelopez-E4S/class_datascience/raw/main/GS_annual-report-2020.pdf\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the PDF file content from the response content\n",
    "    pdf_content = response.content\n",
    "    # Save the PDF file to disk\n",
    "    with open(\"GS_annual_report_2020.pdf\", \"wb\") as f:\n",
    "        f.write(pdf_content)\n",
    "    print(\"PDF file downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to download the PDF file. Error code: {response.status_code}\")\n",
    "    \n",
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "\n",
    "# Open the input PDF file\n",
    "infile = PdfReader(\"GS_annual_report_2020.pdf\", \"rb\")\n",
    "\n",
    "# Create a new PDF writer\n",
    "output = PdfWriter()\n",
    "\n",
    "# Loop through all pages and add them to the new PDF writer\n",
    "for i, page in enumerate(infile.pages):\n",
    "    if (i < 67): # define which pages of the report the model has to extract --> only the relevant pages \n",
    "        output.add_page(page)\n",
    "\n",
    "# Write the output PDF to a file\n",
    "with open(\"GS_annual_report_2020_trimmed.pdf\", \"wb\") as f:\n",
    "    output.write(f)\n",
    "    \n",
    "# Load PDF file\n",
    "pdf = PdfReader(\"GS_annual_report_2020_trimmed.pdf\", \"rb\")\n",
    "\n",
    "# Loop through all pages and extract each sentence\n",
    "sentences = []\n",
    "for page in pdf.pages:\n",
    "    text = page.extract_text()\n",
    "    page_sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    sentences.extend(page_sentences)\n",
    "\n",
    "# Replace all '\\n' with spaces in each sentence\n",
    "sentences = [re.sub(r\"\\n\", \" \", s) for s in sentences]\n",
    "\n",
    "# Filter out all sentences with less than 5 words\n",
    "sentences = [s for s in sentences if  5 < len(s.split()) < 50]\n",
    "\n",
    "\n",
    "# Create a DataFrame of the extracted sentences\n",
    "df_gs_20 = pd.DataFrame(sentences, columns=[\"Sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ACwqPKoq0DR7",
   "metadata": {
    "id": "ACwqPKoq0DR7"
   },
   "source": [
    "With all the sentences from the relevant sections of the annual reports now compiled in a dataframe, we can utilize the previously established function to predict each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0065e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "5f0065e0",
    "outputId": "cda62634-2276-4b82-c989-65cbaedddb7d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goldman Sachs 2020 Annual Report 1 Last year ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Throughout my more-than-35-year   career, ther...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The contrast between the hardship imposed on a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The pandemic put enormous strain on everyone, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>And though I was pleased to see central banks ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>In the preceding paragraphs, square footage fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>We regularly evaluate our space capacityin rel...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>We mayincur exit costs in the future if we (i)...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187</th>\n",
       "      <td>These costs may bematerial to our operating re...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188</th>\n",
       "      <td>Goldman Sachs 2020 Form 10-K 51-&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1189 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 prompt pred\n",
       "0      Goldman Sachs 2020 Annual Report 1 Last year ...    0\n",
       "1     Throughout my more-than-35-year   career, ther...    0\n",
       "2     The contrast between the hardship imposed on a...    0\n",
       "3     The pandemic put enormous strain on everyone, ...    0\n",
       "4     And though I was pleased to see central banks ...    0\n",
       "...                                                 ...  ...\n",
       "1184  In the preceding paragraphs, square footage fi...    0\n",
       "1185  We regularly evaluate our space capacityin rel...    0\n",
       "1186  We mayincur exit costs in the future if we (i)...    0\n",
       "1187  These costs may bematerial to our operating re...    0\n",
       "1188                  Goldman Sachs 2020 Form 10-K 51->    0\n",
       "\n",
       "[1189 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt\n",
       "pred        \n",
       " 0      1181\n",
       " 1         8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the prediction function\n",
    "df_gs_20 = openai_predictions_ada(df_gs_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tgdxWte8kLfl",
   "metadata": {
    "id": "tgdxWte8kLfl"
   },
   "outputs": [],
   "source": [
    "# Storing the dataframe with predtictions --> to avoid re-running the model everytime\n",
    "df_gs_20.to_csv('df_gs_20_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H48R9z5h0qkO",
   "metadata": {
    "id": "H48R9z5h0qkO"
   },
   "source": [
    "Now we can count the number of environmental claims (label = 1) predicted by our model. This variable will be used as part of our analysis with Trucost data at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f30b76",
   "metadata": {
    "id": "24f30b76"
   },
   "outputs": [],
   "source": [
    "# Count the number of observation with 1 as a label\n",
    "gs_20_env_claims = df_gs_20[df_gs_20['pred']==' 1'].count()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23df8c43",
   "metadata": {
    "id": "23df8c43"
   },
   "source": [
    "You can find below an example of environmental and non-environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cff6171",
   "metadata": {
    "id": "5cff6171",
    "outputId": "9c0692b5-43e9-4417-b996-35a8ba3d8b20",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green claim:  For example, we have launched partner-led  sustainability councils within each of our divisions.-> \n",
      "\n",
      "Non-green claim:  Throughout my more-than-35-year   career, there have always been disruptions, but this year saw a healthcare crisis that had   a personal impact on millions.->\n"
     ]
    }
   ],
   "source": [
    "#Green claim\n",
    "print('Green claim: ',df_gs_20[(df_gs_20['pred']==' 1')].iloc[1][0],'\\n')\n",
    "\n",
    "#Non-green claim\n",
    "print('Non-green claim: ',df_gs_20[(df_gs_20['pred']==' 0')].iloc[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1309ac97",
   "metadata": {
    "id": "1309ac97"
   },
   "source": [
    "### Annual Report 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ea28bc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "66ea28bc",
    "outputId": "d2ce6b52-2557-41f9-90ac-84e91852f079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file downloaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Set the URL of the PDF file\n",
    "url = \"https://github.com/noelopez-E4S/class_datascience/raw/main/GS_annual-report-2019.pdf\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Get the PDF file content from the response content\n",
    "    pdf_content = response.content\n",
    "    # Save the PDF file to disk\n",
    "    with open(\"GS_annual_report_2019.pdf\", \"wb\") as f:\n",
    "        f.write(pdf_content)\n",
    "    print(\"PDF file downloaded successfully!\")\n",
    "else:\n",
    "    print(f\"Failed to download the PDF file. Error code: {response.status_code}\")\n",
    "    \n",
    "from PyPDF2 import PdfWriter, PdfReader\n",
    "\n",
    "# Open the input PDF file\n",
    "infile = PdfReader(\"GS_annual_report_2019.pdf\", \"rb\")\n",
    "\n",
    "# Create a new PDF writer\n",
    "output = PdfWriter()\n",
    "\n",
    "# Loop through all pages and add them to the new PDF writer\n",
    "for i, page in enumerate(infile.pages):\n",
    "    if (i < 45): # define which pages of the report the model has to extract --> only the relevant pages \n",
    "        output.add_page(page)\n",
    "\n",
    "# Write the output PDF to a file\n",
    "with open(\"GS_annual_report_2019_trimmed.pdf\", \"wb\") as f:\n",
    "    output.write(f)\n",
    "    \n",
    "# Load PDF file\n",
    "pdf = PdfReader(\"GS_annual_report_2019_trimmed.pdf\", \"rb\")\n",
    "\n",
    "# Loop through all pages and extract each sentence\n",
    "sentences = []\n",
    "for page in pdf.pages:\n",
    "    text = page.extract_text()\n",
    "    page_sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    sentences.extend(page_sentences)\n",
    "\n",
    "# Replace all '\\n' with spaces in each sentence\n",
    "sentences = [re.sub(r\"\\n\", \" \", s) for s in sentences]\n",
    "\n",
    "# Filter out all sentences with less than 5 words\n",
    "sentences = [s for s in sentences if  5 < len(s.split()) < 50]\n",
    "\n",
    "\n",
    "# Create a DataFrame of the extracted sentences\n",
    "df_gs_19 = pd.DataFrame(sentences, columns=[\"Sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hIAdfQMo0FBF",
   "metadata": {
    "id": "hIAdfQMo0FBF"
   },
   "source": [
    "With all the sentences from the relevant sections of the annual reports now compiled in a dataframe, we can use the previously established function to predict each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac82945",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "id": "eac82945",
    "outputId": "1d37e451-b907-412d-c9f3-dee5b2dd1176"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Goldman Sachs 2019 Annual ReportThe Goldman Sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This includes pressure  on the nonprofit secto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Government action  generally has been swift an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This fluid and  historic situation is having a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As a firm, we are taking actions to support ou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>New and prospective liquidity-relatedregulatio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>Given the overlap and complexinteractions amon...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>We face enhanced risks as new business initiat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>A number of our recent and planned business in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>For example, we continue to transactbusiness a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt pred\n",
       "0    Goldman Sachs 2019 Annual ReportThe Goldman Sa...    0\n",
       "1    This includes pressure  on the nonprofit secto...    0\n",
       "2    Government action  generally has been swift an...    0\n",
       "3    This fluid and  historic situation is having a...    0\n",
       "4    As a firm, we are taking actions to support ou...    0\n",
       "..                                                 ...  ...\n",
       "817  New and prospective liquidity-relatedregulatio...    0\n",
       "818  Given the overlap and complexinteractions amon...    0\n",
       "819  We face enhanced risks as new business initiat...    0\n",
       "820  A number of our recent and planned business in...    0\n",
       "821  For example, we continue to transactbusiness a...    0\n",
       "\n",
       "[822 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      prompt\n",
       "pred        \n",
       " 0       820\n",
       " 1         2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calling the prediction function\n",
    "df_gs_19 = openai_predictions_ada(df_gs_19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UA4bGvNuksf7",
   "metadata": {
    "id": "UA4bGvNuksf7"
   },
   "outputs": [],
   "source": [
    "# Storing the dataframe with predtictions --> to avoid re-running the model everytime\n",
    "df_gs_19.to_csv('df_gs_19_ada.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "o-b6--9b0r5H",
   "metadata": {
    "id": "o-b6--9b0r5H"
   },
   "source": [
    "Now we can count the number of environmental claims (label = 1) predicted by our model. This variable will be used as part of our analysis with Trucost data at the end of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5259ae63",
   "metadata": {
    "id": "5259ae63"
   },
   "outputs": [],
   "source": [
    "# Count the number of observation with 1 as a label\n",
    "gs_19_env_claims = df_gs_19[df_gs_19['pred']==' 1'].count()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aac996",
   "metadata": {
    "id": "b3aac996"
   },
   "source": [
    "You can find below an example of environmental and non-environmental claims:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad84782f",
   "metadata": {
    "id": "ad84782f",
    "outputId": "5f714634-3a45-4058-a75c-cfcf3ae30ec2",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Green claim:  We are  focused on ensuring our efforts in this area are aligned  with and accretive to our overall sustainability objectives.-> \n",
      "\n",
      "Non-green claim:  This includes pressure  on the nonprofit sector, which provides critical services to the most vulnerable.->\n"
     ]
    }
   ],
   "source": [
    "#Green claim\n",
    "print('Green claim: ',df_gs_19[(df_gs_19['pred']==' 1')].iloc[1][0],'\\n')\n",
    "\n",
    "#Non-green claim\n",
    "print('Non-green claim: ',df_gs_19[(df_gs_19['pred']==' 0')].iloc[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "864d5fc8",
   "metadata": {
    "id": "864d5fc8"
   },
   "source": [
    "# Banks Annual Reports - Comprehensive analysis \n",
    "\n",
    "In this section, we will perform an analysis by integrating the predictions of our previously conducted model in the notebook with the climatic data obtained from Trucost. These climate data include the climate performance of all the banks investigated in our study. Our objective is to compare this climate data with the number of environmental claims identified by our GPT-3 Text Classifier within the 10 annual reports.\n",
    "\n",
    "First, we import the Trucost data, was provided by Dr. Boris Thurm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78554b5f",
   "metadata": {
    "id": "78554b5f"
   },
   "outputs": [],
   "source": [
    "# Import Trucot data\n",
    "data = pd.read_csv(\"companies_environmental-performance.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05f1215",
   "metadata": {
    "id": "a05f1215"
   },
   "source": [
    "### First analysis: Absolute YoY comparison\n",
    "\n",
    "During the initial analysis, our focus will be on examining each selected bank individually. We will compare the variations in their number of environmental claims between two consecutive years with the corresponding changes in their CO2 emissions over the same period. The objective of this comparative assessment is to determine whether there is alignment or disparity between the bank's increased emphasis on climate change through environmental claims in their annual reports and the actual trajectory of their CO2 emissions. If we observe a noteworthy increase in environmental claims accompanied by a simultaneous rise in CO2 emissions, it could raise concerns regarding possible greenwashing practices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AG4TfLZZ4QWz",
   "metadata": {
    "id": "AG4TfLZZ4QWz"
   },
   "source": [
    "In the next cell, a function is established to retrieve form trucost climate data for a specific bank and a particular year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd311f12",
   "metadata": {
    "id": "fd311f12"
   },
   "outputs": [],
   "source": [
    "def calculate_carbon_footprint(company_name, data, year):\n",
    "    \"\"\"\n",
    "    Calculates the sum of 'Carbon-Scope 1 (tonnes CO2e)', 'Carbon-Scope 2 (tonnes CO2e)',\n",
    "    and 'Carbon-Scope 3 (tonnes CO2e)' for a given company and year.\n",
    "    \n",
    "    Args:\n",
    "        company_name (str): The name of the company to calculate the carbon footprint for.\n",
    "        data (pandas.DataFrame): The DataFrame containing the environmental performance data.\n",
    "        year (int): The year for which to calculate the carbon footprint. Default is 2020.\n",
    "        \n",
    "    Returns:\n",
    "        float: The sum of 'Carbon-Scope 1 (tonnes CO2e)', 'Carbon-Scope 2 (tonnes CO2e)',\n",
    "            and 'Carbon-Scope 3 (tonnes CO2e)' for the given company and year.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter the DataFrame to get rows for the given company and year, and columns for the carbon scopes\n",
    "    company_data = data[(data['Company'] == company_name) & (data['Financial Year'] == year)][['Carbon-Scope 1  (tonnes CO2e)',\n",
    "                                                                                              'Carbon-Scope 2  (tonnes CO2e)',\n",
    "                                                                                              'Carbon-Scope 3 (tonnes CO2e)']]\n",
    "    \n",
    "    # Check that the company has a non-null value in each of the carbon scope columns\n",
    "    if company_data.isnull().values.any():\n",
    "        raise ValueError(\"Company has a missing value in one or more carbon scope columns\")\n",
    "    \n",
    "    # Calculate the sum of the carbon scope columns for the given company and year\n",
    "    carbon_footprint = company_data.sum().sum()\n",
    "    \n",
    "    return carbon_footprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6O5tE-235oPm",
   "metadata": {
    "id": "6O5tE-235oPm"
   },
   "source": [
    "Now we can use the function to retrieve the relevant data for the analyzed banks and the specified years.\n",
    "\n",
    "Note: In the case of UBS for the year 2019, we had to manually import the data. Please refer to the next box for detailed explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77bfc4b",
   "metadata": {
    "id": "f77bfc4b"
   },
   "outputs": [],
   "source": [
    "# Calling the corresponding function with the comapany name and the year \n",
    "ubs_20_co2 = calculate_carbon_footprint(\"UBS Group AG\", data, 2020)\n",
    "ubs_19_co2 = (11320 + 142636 + 576277) # see comment below\n",
    "cs_20_co2 = calculate_carbon_footprint(\"Credit Suisse Group AG\", data, 2020)\n",
    "cs_19_co2 = calculate_carbon_footprint(\"Credit Suisse Group AG\", data, 2019)\n",
    "bcv_20_co2 = calculate_carbon_footprint(\"Banque Cantonale Vaudoise\", data, 2020)\n",
    "bcv_19_co2 = calculate_carbon_footprint(\"Banque Cantonale Vaudoise\", data, 2019)\n",
    "jpm_20_co2 = calculate_carbon_footprint(\"JPMorgan Chase & Co.\", data, 2020)\n",
    "jpm_19_co2 = calculate_carbon_footprint(\"JPMorgan Chase & Co.\", data, 2019)\n",
    "gs_20_co2 = calculate_carbon_footprint(\"The Goldman Sachs Group, Inc.\", data, 2020)\n",
    "gs_19_co2 = calculate_carbon_footprint(\"The Goldman Sachs Group, Inc.\", data, 2019)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec56de67",
   "metadata": {
    "id": "ec56de67"
   },
   "source": [
    "The dataset provided does not include the CO2 emissions for UBS Group for 2019. However, through the Sustainable Finance course taught by Eric Jondeau, we were provided with a Trucost Dataset that includes the CO2 emissions for UBS Group in 2019. To ensure the accuracy of this data, we compared it to the data from the provided dataset for the year 2018 and found that they were identical (see code in following cells). Therefore, we feel confident in incorporating the CO2 emissions data for UBS Group in 2019 from the other Trucost dataset. We remain at disposal to provide the corresponding file upon request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AhcLGykR6ko_",
   "metadata": {
    "id": "AhcLGykR6ko_",
    "outputId": "99ac05bd-e921-4ba2-8d5b-f9a7b0c19a6f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005818.099\n",
      "1005818.099\n"
     ]
    }
   ],
   "source": [
    "# check accuracy file provided by Prof. Jondeau for 2018\n",
    "trucost_ubs_18_jondeau = 11521.9961 + 150957 + 843339.1029 # --> manual imported data from Prof. Jondeau dataset\n",
    "print(trucost_ubs_18_jondeau)\n",
    "\n",
    "# from the dataset provided in ML\n",
    "ubs_18_co2 = calculate_carbon_footprint(\"UBS Group AG\", data, 2018)\n",
    "print(ubs_18_co2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LkLTexswBOIa",
   "metadata": {
    "id": "LkLTexswBOIa"
   },
   "source": [
    "Now that the accuracy is verified, we have all the measures in hand. We can now present them in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f033fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "70f033fa",
    "outputId": "a866692a-21fc-4d87-b82c-cfe2cb061d54"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Year</th>\n",
       "      <th>Environmental Claims</th>\n",
       "      <th>CO2 Emissions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UBS</td>\n",
       "      <td>2019</td>\n",
       "      <td>66</td>\n",
       "      <td>730233.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UBS</td>\n",
       "      <td>2020</td>\n",
       "      <td>85</td>\n",
       "      <td>1065783.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Credit Suisse</td>\n",
       "      <td>2019</td>\n",
       "      <td>21</td>\n",
       "      <td>735218.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Credit Suisse</td>\n",
       "      <td>2020</td>\n",
       "      <td>29</td>\n",
       "      <td>678125.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Banque Cantonale Vaudoise</td>\n",
       "      <td>2019</td>\n",
       "      <td>16</td>\n",
       "      <td>27463.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Banque Cantonale Vaudoise</td>\n",
       "      <td>2020</td>\n",
       "      <td>34</td>\n",
       "      <td>29505.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>3875536.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>JPMorgan Chase &amp; Co.</td>\n",
       "      <td>2020</td>\n",
       "      <td>22</td>\n",
       "      <td>3479547.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Goldman Sachs Group, Inc.</td>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1313970.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Goldman Sachs Group, Inc.</td>\n",
       "      <td>2020</td>\n",
       "      <td>8</td>\n",
       "      <td>1327399.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Company  Year  Environmental Claims  CO2 Emissions\n",
       "0                            UBS  2019                    66      730233.00\n",
       "1                            UBS  2020                    85     1065783.41\n",
       "2                  Credit Suisse  2019                    21      735218.33\n",
       "3                  Credit Suisse  2020                    29      678125.10\n",
       "4      Banque Cantonale Vaudoise  2019                    16       27463.08\n",
       "5      Banque Cantonale Vaudoise  2020                    34       29505.24\n",
       "6           JPMorgan Chase & Co.  2019                    10     3875536.24\n",
       "7           JPMorgan Chase & Co.  2020                    22     3479547.33\n",
       "8  The Goldman Sachs Group, Inc.  2019                     2     1313970.93\n",
       "9  The Goldman Sachs Group, Inc.  2020                     8     1327399.42"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the display format for float values\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "# Create a dictionary with the data\n",
    "new_data = {\n",
    "    'Company': ['UBS', 'UBS', 'Credit Suisse', 'Credit Suisse', 'Banque Cantonale Vaudoise', 'Banque Cantonale Vaudoise', \"JPMorgan Chase & Co.\", \"JPMorgan Chase & Co.\", \"The Goldman Sachs Group, Inc.\", \"The Goldman Sachs Group, Inc.\"],\n",
    "    'Year': [2019, 2020, 2019, 2020, 2019, 2020, 2019, 2020, 2019, 2020],\n",
    "    'Environmental Claims': [ubs_19_env_claims, ubs_20_env_claims, cs_19_env_claims, cs_20_env_claims, bcv_19_env_claims, bcv_20_env_claims, jpm_19_env_claims, jpm_20_env_claims, gs_19_env_claims, gs_20_env_claims],\n",
    "    'CO2 Emissions': [ubs_19_co2, ubs_20_co2, cs_19_co2, cs_20_co2, bcv_19_co2, bcv_20_co2, jpm_19_co2, jpm_20_co2, gs_19_co2, gs_20_co2]\n",
    "}\n",
    "\n",
    "# Create a pandas dataframe\n",
    "df = pd.DataFrame(new_data)\n",
    "\n",
    "# Display the dataframe\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jc6Tpuhg7zu_",
   "metadata": {
    "id": "Jc6Tpuhg7zu_"
   },
   "source": [
    "For the analysis this table, we kindly refer the reader of this notebook to the accompanying README file, which can be found on the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "VUkLjYfB4ZAc",
   "metadata": {
    "id": "VUkLjYfB4ZAc"
   },
   "outputs": [],
   "source": [
    "# Store the table \n",
    "df.to_csv('company_claims_emissions')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3620fd",
   "metadata": {
    "id": "2b3620fd"
   },
   "source": [
    "### Second analysis: Industry ranking\n",
    "\n",
    "In this second analysis, we will expand our examination to the industry level, considering the diverse sizes of banks to account for differences in the amount emissions. To accomplish this, we will introduce a metric called CO2 intensity for each bank, which normalizes individual CO2 emissions based on the company's revenues. This normalization helps mitigate the influence of size discrepancies and enables meaningful comparisons across different companies within the same industry. By using this metric, we will establish a ranking of banks according to their CO2 intensity and compare it with the ranking based on the number of environmental claims. The purpose of this comparison is to identify cases where a bank, despite having a low CO2 intensity rank, extensively emphasizes its climate ambitions. Such disparities could potentially indicate instances of greenwashing practices. This analysis will span a two-year period as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d36878d",
   "metadata": {
    "id": "9d36878d"
   },
   "outputs": [],
   "source": [
    "# Create a sub-data set with companies only active in the \"Financials\" sector\n",
    "financial_companies = data[data['GICS Sector Name'] == 'Financials']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-jyJHCGb8_Pw",
   "metadata": {
    "id": "-jyJHCGb8_Pw"
   },
   "source": [
    "Now, we create a new function that will calculates the cumulative carbon intensity for a given company and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013e1f96",
   "metadata": {
    "id": "013e1f96"
   },
   "outputs": [],
   "source": [
    "def calculate_total_carbon_intensity(company_name, year):\n",
    "    \"\"\"\n",
    "    Calculates the total carbon intensity for a given company and year.\n",
    "    \n",
    "    Args:\n",
    "        company_name (str): The name of the company to calculate the total carbon intensity for.\n",
    "        data (pandas.DataFrame): The DataFrame containing the environmental performance data.\n",
    "        year (int): The year for which to calculate the total carbon intensity.\n",
    "        \n",
    "    Returns:\n",
    "        float: The sum of carbon intensity for the given company and year.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter the DataFrame to get rows for the given company and year, and select the specified columns\n",
    "    company_data = financial_companies[(financial_companies['Company'] == company_name) & (data['Financial Year'] == year)][['Carbon Intensity-Scope 1 (tonnes CO2e/USD mn)',\n",
    "                                                                                               'Carbon Intensity-Scope 2 (tonnes CO2e/USD mn)',\n",
    "                                                                                               'Carbon Intensity-Scope 3 (tonnes CO2e/USD mn)']]\n",
    "    \n",
    "    # Check if the filtered DataFrame is empty\n",
    "    if company_data.empty:\n",
    "        raise ValueError(\"No data found for the specified company and year.\")\n",
    "    \n",
    "    # Calculate the sum of the specified columns for the given company and year\n",
    "    total_carbon_intensity = company_data.sum().sum()\n",
    "    \n",
    "    return total_carbon_intensity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MV_K8PtD9T_3",
   "metadata": {
    "id": "MV_K8PtD9T_3"
   },
   "source": [
    "Now we can use the function to retrieve the relevant data for the analyzed banks and the specified years.\n",
    "\n",
    "Note: Similar to previous instances, we have an issue with UBS for the year 2019. Consequently, we used the data provided by Prof. Jondeau, which also included metrics related to CO2 intensity. We also perform an accuraycy check between the two files for the year of 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f778a",
   "metadata": {
    "id": "110f778a"
   },
   "outputs": [],
   "source": [
    "# Calling the corresponding function with the comapany name and the year \n",
    "jpm_20_intensity = calculate_total_carbon_intensity('JPMorgan Chase & Co.', 2020)\n",
    "jpm_19_intensity = calculate_total_carbon_intensity('JPMorgan Chase & Co.', 2019)\n",
    "gs_19_intensity = calculate_total_carbon_intensity('The Goldman Sachs Group, Inc.', 2020)\n",
    "gs_20_intensity = calculate_total_carbon_intensity('The Goldman Sachs Group, Inc.', 2019)\n",
    "ubs_20_intensity = calculate_total_carbon_intensity('UBS Group AG', 2020)\n",
    "ubs_19_intensity = 0.5851 + 7.3726 + 29.7684 # check for accuracy bellow\n",
    "bcv_20_intensity = calculate_total_carbon_intensity('Banque Cantonale Vaudoise', 2020)\n",
    "bcv_19_intensity = calculate_total_carbon_intensity('Banque Cantonale Vaudoise', 2019)\n",
    "cs_19_intensity = calculate_total_carbon_intensity('Credit Suisse Group AG', 2019)\n",
    "cs_20_intensity = calculate_total_carbon_intensity('Credit Suisse Group AG', 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3D5WYexAABX6",
   "metadata": {
    "id": "3D5WYexAABX6",
    "outputId": "8b7e2c6d-72a8-457b-dd89-f278331a7b61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.364043950698395\n",
      "37.364043947\n"
     ]
    }
   ],
   "source": [
    "# check accuracy file provided by Prof. Jondeau for 2018\n",
    "trucost_ubs_18_intensity_jondeau = 0.428018116901008 + 5.60773761006559+ 31.3282882237318 # --> manual imported data from Prof. Jondeau dataset\n",
    "print(trucost_ubs_18_intensity_jondeau)\n",
    "\n",
    "# from the dataset provided in ML\n",
    "ubs_18_co2_intensity = ubs_20_intensity = calculate_total_carbon_intensity('UBS Group AG', 2018)\n",
    "print(ubs_18_co2_intensity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eKgewxWpBqS_",
   "metadata": {
    "id": "eKgewxWpBqS_"
   },
   "source": [
    "Now that the accuracy is also verified for carbon intensity, we have all the measures in hand. We can now present them in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3b6dde",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "fb3b6dde",
    "outputId": "c66626bb-58c3-4e09-b042-8308b03301d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "      <th>CO2 Intensity</th>\n",
       "      <th>Rank - CO2 Intensity</th>\n",
       "      <th>Environmental Claims</th>\n",
       "      <th>Rank - Env. Claims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020</td>\n",
       "      <td>UBS</td>\n",
       "      <td>37.36</td>\n",
       "      <td>9</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>UBS</td>\n",
       "      <td>37.73</td>\n",
       "      <td>10</td>\n",
       "      <td>66</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020</td>\n",
       "      <td>BCV</td>\n",
       "      <td>29.31</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>Credit Suisse</td>\n",
       "      <td>30.34</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020</td>\n",
       "      <td>JPMorgan Chase</td>\n",
       "      <td>34.09</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>Credit Suisse</td>\n",
       "      <td>31.75</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>BCV</td>\n",
       "      <td>29.70</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>JPMorgan Chase</td>\n",
       "      <td>33.52</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>35.95</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>32.01</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year            Name  CO2 Intensity  Rank - CO2 Intensity   \n",
       "0  2020             UBS          37.36                     9  \\\n",
       "1  2019             UBS          37.73                    10   \n",
       "2  2020             BCV          29.31                     1   \n",
       "3  2020   Credit Suisse          30.34                     3   \n",
       "4  2020  JPMorgan Chase          34.09                     7   \n",
       "5  2019   Credit Suisse          31.75                     4   \n",
       "6  2019             BCV          29.70                     2   \n",
       "7  2019  JPMorgan Chase          33.52                     6   \n",
       "8  2020   Goldman Sachs          35.95                     8   \n",
       "9  2019   Goldman Sachs          32.01                     5   \n",
       "\n",
       "   Environmental Claims  Rank - Env. Claims  \n",
       "0                    85                   1  \n",
       "1                    66                   2  \n",
       "2                    34                   3  \n",
       "3                    29                   4  \n",
       "4                    22                   5  \n",
       "5                    21                   6  \n",
       "6                    16                   7  \n",
       "7                    10                   8  \n",
       "8                     8                   9  \n",
       "9                     2                  10  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary with the given variables and their corresponding values\n",
    "data = {\n",
    "    'Year': [2020, 2019, 2020, 2019, 2020, 2019, 2020, 2019, 2020, 2019],\n",
    "    'Name': ['JPMorgan Chase', 'JPMorgan Chase', 'Goldman Sachs', 'Goldman Sachs', 'UBS', 'UBS', 'BCV', 'BCV', 'Credit Suisse', 'Credit Suisse'],\n",
    "    'CO2 Intensity': [jpm_20_intensity, jpm_19_intensity, gs_20_intensity, gs_19_intensity, ubs_20_intensity, ubs_19_intensity, bcv_20_intensity, bcv_19_intensity, cs_20_intensity, cs_19_intensity],\n",
    "    'Environmental Claims': [jpm_20_env_claims, jpm_19_env_claims, gs_20_env_claims, gs_19_env_claims, ubs_20_env_claims, ubs_19_env_claims, bcv_20_env_claims, bcv_19_env_claims, cs_20_env_claims, cs_19_env_claims]\n",
    "\n",
    "}\n",
    "# Create a DataFrame from the data dictionary\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sort the DataFrame by 'CO2 Intensity' in ascending order\n",
    "df_sorted = df.sort_values(by='CO2 Intensity', ascending=True)\n",
    "\n",
    "# Add a 'Rank - CO2 Intensity' column based on the sorted order\n",
    "df_sorted['Rank - CO2 Intensity'] = range(1, len(df_sorted) + 1)\n",
    "\n",
    "# Reorder the columns\n",
    "df_sorted = df_sorted[['Year', 'Name', 'CO2 Intensity', 'Rank - CO2 Intensity', 'Environmental Claims']]\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df_sorted = df_sorted.reset_index(drop=True)\n",
    "\n",
    "# Sort the DataFrame by 'Environmental Claims' in descending order\n",
    "df_sorted = df_sorted.sort_values(by='Environmental Claims', ascending=False)\n",
    "\n",
    "# Add a 'Rank - Env. Claims' column based on the sorted order\n",
    "df_sorted['Rank - Env. Claims'] = range(1, len(df_sorted) + 1)\n",
    "\n",
    "# Reorder the columns\n",
    "df_sorted = df_sorted[['Year', 'Name', 'CO2 Intensity', 'Rank - CO2 Intensity', 'Environmental Claims', 'Rank - Env. Claims']]\n",
    "\n",
    "# Reset the index of the DataFrame\n",
    "df_sorted = df_sorted.reset_index(drop=True)\n",
    "\n",
    "# Print the sorted and ranked DataFrame\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ahinlAd74yL",
   "metadata": {
    "id": "3ahinlAd74yL"
   },
   "source": [
    "For the analysis this table, we kindly refer the reader of this notebook to the accompanying README file, which can be found on the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69392aff",
   "metadata": {
    "id": "69392aff"
   },
   "outputs": [],
   "source": [
    "# Store the table\n",
    "df_sorted.to_csv('industry_ranking')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
